{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kleYrDbGhdDt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import json\n",
        "from scipy.interpolate import interp1d\n",
        "import seaborn as sns\n",
        "\n",
        "def read_monitor_files(log_dir):\n",
        "    \"\"\"\n",
        "    Read all monitor CSV files from the log directory.\n",
        "    Monitor files are saved as 0.monitor.csv, 1.monitor.csv, etc.\n",
        "    \"\"\"\n",
        "    monitor_files = glob(os.path.join(log_dir, \"*.monitor.csv\"))\n",
        "    if not monitor_files:\n",
        "        # Try subdirectories\n",
        "        monitor_files = glob(os.path.join(log_dir, \"*\", \"*.monitor.csv\"))\n",
        "\n",
        "    if not monitor_files:\n",
        "        raise ValueError(f\"No monitor files found in {log_dir}\")\n",
        "\n",
        "    all_data = []\n",
        "\n",
        "    for file_path in monitor_files:\n",
        "        # Read the CSV file\n",
        "        try:\n",
        "            # Monitor files have a header with metadata\n",
        "            with open(file_path, 'r') as f:\n",
        "                # Skip the first line which contains metadata\n",
        "                f.readline()\n",
        "                df = pd.read_csv(f)\n",
        "\n",
        "            # Add cumulative timesteps\n",
        "            df['cumulative_timesteps'] = df['l'].cumsum()\n",
        "            all_data.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return all_data\n",
        "\n",
        "def aggregate_data(all_data, window_size=100, num_points=200):\n",
        "    \"\"\"\n",
        "    Aggregate data from multiple processes and compute statistics.\n",
        "    \"\"\"\n",
        "    # Combine all timesteps and rewards\n",
        "    all_timesteps = []\n",
        "    all_rewards = []\n",
        "\n",
        "    for df in all_data:\n",
        "        all_timesteps.extend(df['cumulative_timesteps'].values)\n",
        "        all_rewards.extend(df['r'].values)\n",
        "\n",
        "    # Sort by timesteps\n",
        "    sorted_indices = np.argsort(all_timesteps)\n",
        "    all_timesteps = np.array(all_timesteps)[sorted_indices]\n",
        "    all_rewards = np.array(all_rewards)[sorted_indices]\n",
        "\n",
        "    # Create bins for aggregation\n",
        "    max_timesteps = all_timesteps[-1]\n",
        "    timestep_bins = np.linspace(0, max_timesteps, num_points)\n",
        "\n",
        "    mean_rewards = []\n",
        "    std_rewards = []\n",
        "    timesteps_plot = []\n",
        "\n",
        "    for i in range(len(timestep_bins) - 1):\n",
        "        bin_start = timestep_bins[i]\n",
        "        bin_end = timestep_bins[i + 1]\n",
        "\n",
        "        # Get rewards in this bin\n",
        "        mask = (all_timesteps >= bin_start) & (all_timesteps < bin_end)\n",
        "        bin_rewards = all_rewards[mask]\n",
        "\n",
        "        if len(bin_rewards) > 0:\n",
        "            # Use a rolling window for smoother curves\n",
        "            if i > 0:\n",
        "                # Look back to get more samples for statistics\n",
        "                lookback_start = max(0, i - window_size // 2)\n",
        "                lookback_mask = (all_timesteps >= timestep_bins[lookback_start]) & (all_timesteps < bin_end)\n",
        "                window_rewards = all_rewards[lookback_mask]\n",
        "\n",
        "                if len(window_rewards) > 0:\n",
        "                    mean_rewards.append(np.mean(window_rewards))\n",
        "                    std_rewards.append(np.std(window_rewards) / np.sqrt(len(window_rewards)))  # Standard error\n",
        "                    timesteps_plot.append((bin_start + bin_end) / 2)\n",
        "\n",
        "    return np.array(timesteps_plot), np.array(mean_rewards), np.array(std_rewards)\n",
        "\n",
        "def get_method_colors(all_method_names):\n",
        "    \"\"\"\n",
        "    Create a consistent color mapping for all methods across plots.\n",
        "    Following the format from the first script.\n",
        "    \"\"\"\n",
        "    # Define specific colors for certain methods to ensure consistency\n",
        "    specific_colors = {\n",
        "        'LP': '#d62728',    # Red color for LP\n",
        "        'AMA': '#ff7f0e',   # Orange color for AMA\n",
        "        'Ensemble': '#1f77b4',  # Blue color for Ensemble\n",
        "        'MSE': '#2ca02c',   # Green color for MSE\n",
        "        'IDF': '#9467bd',   # Purple color for IDF\n",
        "        'RND': '#8c564b'    # Brown color for RND\n",
        "    }\n",
        "\n",
        "    # Available colors for automatic assignment (excluding already used specific colors)\n",
        "    available_colors = ['#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
        "\n",
        "    method_colors = {}\n",
        "    auto_color_idx = 0\n",
        "\n",
        "    for method_name in sorted(all_method_names):\n",
        "        if method_name in specific_colors:\n",
        "            method_colors[method_name] = specific_colors[method_name]\n",
        "        else:\n",
        "            method_colors[method_name] = available_colors[auto_color_idx % len(available_colors)]\n",
        "            auto_color_idx += 1\n",
        "\n",
        "    return method_colors\n",
        "\n",
        "def get_display_name(method_name):\n",
        "    \"\"\"\n",
        "    Convert method names to display names for the legend.\n",
        "\n",
        "    Args:\n",
        "        method_name: Original method name\n",
        "\n",
        "    Returns:\n",
        "        str: Display name for the legend\n",
        "    \"\"\"\n",
        "    if method_name == 'LP':\n",
        "        return 'LPM(ours)'\n",
        "    return method_name\n",
        "\n",
        "def plot_four_environment_comparison(experiment_dicts, env_titles, save_dir=\"comparison_plots\"):\n",
        "    \"\"\"\n",
        "    Plot comparison of exploration methods across four different environments side by side.\n",
        "    Following the format from the first script but adapted for exploration curves.\n",
        "\n",
        "    Args:\n",
        "        experiment_dicts: List of 4 dictionaries, each mapping method names to log directories\n",
        "        env_titles: List of 4 environment titles\n",
        "        save_dir: Directory to save the plots\n",
        "    \"\"\"\n",
        "\n",
        "    plt.style.use('default')\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 10,\n",
        "        'font.family': 'serif',\n",
        "        'font.serif': ['Times New Roman', 'Times', 'serif'],\n",
        "        'mathtext.fontset': 'stix',\n",
        "        'axes.linewidth': 0.8,\n",
        "        'grid.linewidth': 0.5,\n",
        "        'lines.linewidth': 1.5,\n",
        "    })\n",
        "\n",
        "    # Create save directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Get all unique method names for consistent coloring\n",
        "    all_methods = set()\n",
        "    for exp_dict in experiment_dicts:\n",
        "        all_methods.update(exp_dict.keys())\n",
        "\n",
        "    # Remove 'random' from methods if it exists (we'll handle it separately)\n",
        "    if 'random' in all_methods:\n",
        "        all_methods.remove('random')\n",
        "\n",
        "    method_colors = get_method_colors(all_methods)\n",
        "\n",
        "    # Create figure with 4 subplots side by side\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(32, 7))\n",
        "\n",
        "    # Store all plot handles for legend - use dictionaries for organized collection\n",
        "    method_handles_dict = {}\n",
        "    random_handle = None\n",
        "\n",
        "    # Plot each environment\n",
        "    for idx, (experiment_dict, env_title) in enumerate(zip(experiment_dicts, env_titles)):\n",
        "        ax = axes[idx]\n",
        "\n",
        "        if not experiment_dict:\n",
        "            ax.text(0.5, 0.5, f'No data available\\nfor {env_title}',\n",
        "                   ha='center', va='center', transform=ax.transAxes,\n",
        "                   fontsize=15, style='italic')\n",
        "            ax.set_title(env_title, fontsize=35, fontweight='medium')\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing {env_title}...\")\n",
        "\n",
        "        # Track max timesteps for random baseline\n",
        "        max_timesteps = 0\n",
        "\n",
        "        # Plot each method in this environment\n",
        "        for method_name, log_dir in experiment_dict.items():\n",
        "            # Skip random for now, we'll add it as baseline\n",
        "            if method_name.lower() == 'random':\n",
        "                continue\n",
        "\n",
        "            print(f\"  Processing {method_name} from {log_dir}...\")\n",
        "\n",
        "            try:\n",
        "                # Read monitor files\n",
        "                all_data = read_monitor_files(log_dir)\n",
        "\n",
        "                # Aggregate data\n",
        "                timesteps, mean_rewards, std_rewards = aggregate_data(all_data)\n",
        "\n",
        "                # Convert timesteps to steps (keep as is or divide by 1000 for thousands)\n",
        "                timesteps_steps = timesteps * 1000000 / 16000\n",
        "\n",
        "                # Update max timesteps for baseline line\n",
        "                if len(timesteps_steps) > 0:\n",
        "                    max_timesteps = max(max_timesteps, timesteps_steps[-1])\n",
        "\n",
        "                color = method_colors[method_name]\n",
        "\n",
        "                # Plot mean line\n",
        "                line = ax.plot(timesteps_steps, mean_rewards,\n",
        "                              color=color,\n",
        "                              linestyle='-',\n",
        "                              linewidth=3,\n",
        "                              label=method_name,\n",
        "                              alpha=0.9)[0]\n",
        "\n",
        "                # Plot confidence interval (reduced std for tighter bands)\n",
        "                ax.fill_between(timesteps_steps,\n",
        "                               mean_rewards - std_rewards,\n",
        "                               mean_rewards + std_rewards,\n",
        "                               color=color,\n",
        "                               alpha=0.1)\n",
        "\n",
        "                # Collect handles for legend (only from first subplot to avoid duplicates)\n",
        "                if idx == 0 and method_name not in method_handles_dict:\n",
        "                    method_handles_dict[method_name] = line\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error processing {method_name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Add random baseline if available\n",
        "        if 'random' in experiment_dict:\n",
        "            random_log_dir = experiment_dict['random']\n",
        "            print(f\"  Adding random baseline from {random_log_dir}...\")\n",
        "\n",
        "            try:\n",
        "                # Compute overall average reward for random baseline\n",
        "                all_data = read_monitor_files(random_log_dir)\n",
        "                all_rewards = []\n",
        "                for df in all_data:\n",
        "                    all_rewards.extend(df['r'].values)\n",
        "\n",
        "                if all_rewards:\n",
        "                    random_avg_reward = np.mean(all_rewards)\n",
        "                    baseline_line = ax.axhline(y=random_avg_reward, color='gray',\n",
        "                                             linestyle='--', linewidth=2,\n",
        "                                             alpha=0.8)\n",
        "\n",
        "                    # Add to legend only from first subplot\n",
        "                    if idx == 0 and random_handle is None:\n",
        "                        random_handle = baseline_line\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error processing random baseline: {e}\")\n",
        "\n",
        "        # Customize each subplot\n",
        "        if idx == 0:  # Only leftmost plot gets y-label\n",
        "            ax.set_ylabel('Extrinsic Reward', fontsize=35, fontweight='medium')\n",
        "        ax.set_title(env_title, fontsize=35, fontweight='medium')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim(left=0)\n",
        "        ax.tick_params(axis='both', which='major', labelsize=25)\n",
        "        ax.xaxis.get_offset_text().set_fontsize(30)\n",
        "        ax.yaxis.get_offset_text().set_fontsize(30)\n",
        "\n",
        "    # Organize legend with specific ordering: No Int Rew first, LPM(ours) last\n",
        "    legend_handles = []\n",
        "    legend_labels = []\n",
        "\n",
        "    # First add \"No Int Rew\" if it exists\n",
        "    if random_handle is not None:\n",
        "        legend_handles.append(random_handle)\n",
        "        legend_labels.append('No Int Rew')\n",
        "\n",
        "    # Then add all methods except LP (sorted)\n",
        "    for method_name in sorted(method_handles_dict.keys()):\n",
        "        if method_name != 'LP':\n",
        "            legend_handles.append(method_handles_dict[method_name])\n",
        "            legend_labels.append(get_display_name(method_name))\n",
        "\n",
        "    # Finally add LP (as LPM(ours)) at the end if it exists\n",
        "    if 'LP' in method_handles_dict:\n",
        "        legend_handles.append(method_handles_dict['LP'])\n",
        "        legend_labels.append(get_display_name('LP'))\n",
        "\n",
        "    # Add single legend at the top of the figure\n",
        "    if legend_handles:\n",
        "        fig.legend(legend_handles, legend_labels,\n",
        "                  loc='upper center', bbox_to_anchor=(0.5, 1.08),\n",
        "                  ncol=len(legend_labels), fontsize=30)\n",
        "\n",
        "    # Adjust layout to make room for legend\n",
        "    fig.text(0.5, -0.04, 'Frames (millions)', ha='center', va='bottom',\n",
        "             fontsize=35, fontweight='medium')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig(os.path.join(save_dir, 'four_environment_exploration_comparison.pdf'),\n",
        "               dpi=1000, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def print_exploration_summary_statistics(experiment_dicts, env_titles):\n",
        "    \"\"\"\n",
        "    Print summary statistics for all methods across all environments.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"SUMMARY STATISTICS - FINAL EXPLORATION PERFORMANCE ACROSS ENVIRONMENTS\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # Get all unique methods\n",
        "    all_methods = set()\n",
        "    for exp_dict in experiment_dicts:\n",
        "        all_methods.update(exp_dict.keys())\n",
        "\n",
        "    # Remove random from main methods\n",
        "    if 'random' in all_methods:\n",
        "        all_methods.remove('random')\n",
        "\n",
        "    # Create header\n",
        "    header = f\"{'Method':<15}\"\n",
        "    for title in env_titles:\n",
        "        header += f\" {title:<20}\"\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "\n",
        "    for method_name in sorted(all_methods):\n",
        "        row = f\"{method_name:<15}\"\n",
        "\n",
        "        for exp_dict in experiment_dicts:\n",
        "            if method_name in exp_dict:\n",
        "                try:\n",
        "                    log_dir = exp_dict[method_name]\n",
        "                    all_data = read_monitor_files(log_dir)\n",
        "                    timesteps, mean_rewards, std_rewards = aggregate_data(all_data)\n",
        "\n",
        "                    if len(mean_rewards) > 0:\n",
        "                        final_reward = mean_rewards[-1]\n",
        "                        row += f\" {final_reward:.1f} ± {std_rewards[-1]:.1f}\".ljust(20)\n",
        "                    else:\n",
        "                        row += \" N/A\".ljust(20)\n",
        "                except:\n",
        "                    row += \" Error\".ljust(20)\n",
        "            else:\n",
        "                row += \" N/A\".ljust(20)\n",
        "\n",
        "        print(row)\n",
        "\n",
        "    print(\"=\"*100)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to create four-environment comparison plots.\n",
        "    Example usage with placeholder experiment dictionaries.\n",
        "    \"\"\"\n",
        "    # Example experiment dictionaries for four environments\n",
        "    # Replace these with your actual log directories\n",
        "\n",
        "    experiment_dict_env1 = {\n",
        "        'LP': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/improve_20250605_210532',\n",
        "        'random': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/random_20250605_210532',\n",
        "        'AMA': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/ama_20250605_210532',\n",
        "        'MSE': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/mse_20250605_234534',\n",
        "        'RND': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/rnd_w_no_noise',\n",
        "        'IDF': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/icm_w_no_noise_w_clip_10eta',\n",
        "        \"Ensemble\": '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ensemble_w_no_noise',\n",
        "        'EDT': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/atari_spaceinvader_ttd_wo_noise',\n",
        "        'EME': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/space_invader_eme_wo_noise'\n",
        "    }\n",
        "\n",
        "    experiment_dict_env2 = {\n",
        "        # 'pure': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ppo_pure_05-29',\n",
        "        'LP': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ppo_improve_w_seed_06_03_noisy',\n",
        "        'random': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/random_noisy_06-03',\n",
        "        # 'ama': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ama_05-29',\n",
        "        # 'ama-with-clip': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ama_with_clip_06_03_w_seed',\n",
        "        'AMA': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ama_with_clip_06_03_w_seed_noisy',\n",
        "        'MSE': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/mse_noisy_20250606_014834',\n",
        "        'RND': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/rnd_w_noise_w_clip',\n",
        "        'IDF': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/idf_w_no_noise_w_clip_10eta',\n",
        "        \"Ensemble\": '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ensemble_w_noise',\n",
        "        \"EDT\": '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/New_spaceinvader/atari_spaceinvader_ttd_w_noise',\n",
        "        'EME': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/space_invader_eme_w_noise'\n",
        "    }\n",
        "\n",
        "    experiment_dict_env3 = {\n",
        "        'LP': '/content/drive/MyDrive/MercedLab/Optimization_explore/log_v2/deterministic/MsPacman/ppo-improvement_20250630_010602',\n",
        "        'random': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v2/random_20250610_223302',\n",
        "        # 'ama': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ama_05-29',\n",
        "        # 'ama-with-clip': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/SpaceInvaders/ama_with_clip_06_03_w_seed',\n",
        "        'AMA': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v2/ama_v2_20250610_223302',\n",
        "        'MSE': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v2/mse_20250610_223302',\n",
        "        # 'unet_larger_clip': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3/unet_20250611_190433',\n",
        "        'IDF': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3/IDF_w_no_noise',\n",
        "        'Ensemble': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3/Ensemble_w_no_noise',\n",
        "        'RND': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3/RND_w_no_noise',\n",
        "        'EDT': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/MsPacman/pacman_tdd_wo_noise',\n",
        "        'EME': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/MsPacman/pacman_eme_wo_noise'\n",
        "    }\n",
        "\n",
        "    experiment_dict_env4 = {\n",
        "        'random': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v2_noisy/random_20250611_021817',\n",
        "        'AMA': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v2_noisy/ama_v2_20250611_021817',\n",
        "        'MSE': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v2_noisy/mse_20250611_021817',\n",
        "        'LP': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v4_noise/improve_20250701_194016',\n",
        "        # 'ppo': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3_noisy/ppo_20250613_190232',\n",
        "        'RND': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3/RND_w_noise',\n",
        "        'Ensemble': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v3/ensemble_w_noise',\n",
        "        'IDF': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/pacman_v4/idf_w_noise',\n",
        "        'EDT': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/MsPacman/pacman_tdd_w_noise',\n",
        "        'EME': '/content/drive/MyDrive/MercedLab/Optimization_explore/logs/MsPacman/pacman_eme_wo_noise'\n",
        "    }\n",
        "\n",
        "    # Environment titles\n",
        "    env_titles = [\"Space Invader\", \"Space Invader w Noise\", \"Ms PacMan\", \"Ms PacMan w Noise\"]\n",
        "\n",
        "    # List of experiment dictionaries\n",
        "    experiment_dicts = [experiment_dict_env1, experiment_dict_env2, experiment_dict_env3, experiment_dict_env4]\n",
        "\n",
        "    print(\"Creating four-environment exploration comparison plots...\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create comparison plots\n",
        "    plot_four_environment_comparison(experiment_dicts, env_titles)\n",
        "\n",
        "    # Print summary statistics\n",
        "    print_exploration_summary_statistics(experiment_dicts, env_titles)\n",
        "\n",
        "    print(f\"\\nComparison plots saved in 'comparison_plots' directory\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}